{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theme = 'plotly_dark'\n",
    "theme = 'seaborn'\n",
    "#theme = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "title = 'Bouts v. Model Pred'\n",
    "\n",
    "path_to_model_def = '/home/kuba/Projects/MedicationTakingData/resmodel' #this is were the .py file is \n",
    "path_to_dir_with_model_pt_file = '/home/kuba/Projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7'\n",
    "\n",
    "#the watch and recoding we willbe evaling\n",
    "WATCH_DIR = '/home/kuba/Documents/Data/Raw/Listerine/3_final/03'\n",
    "recording = '2023-07-18_07_21_53'\n",
    "\n",
    "HERTZ = 100\n",
    "ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING = {\n",
    "    'water':0,\n",
    "    'listerine':1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_window(df, start, window_size):\n",
    "    \"\"\"\n",
    "    Prepare a window of accelerometer and gyroscope data for the model.\n",
    "    \"\"\"\n",
    "    window = df.iloc[start:start + window_size]\n",
    "    # Prepare accelerometer and gyroscope data\n",
    "    X_acc = torch.tensor([window[col].values for col in ['acc_x', 'acc_y', 'acc_z']], dtype=torch.float32)\n",
    "    X_gyro = torch.tensor([window[col].values for col in ['gyro_x', 'gyro_y', 'gyro_z']], dtype=torch.float32)\n",
    "    # Combine [1, 6, window_size]\n",
    "    return torch.cat((X_acc, X_gyro), dim=0).unsqueeze(0)\n",
    "\n",
    "def smooth_predictions(prediction_sum, counts):\n",
    "    \"\"\"\n",
    "    Smooth predictions by averaging, handling divisions by zero.\n",
    "    \"\"\"\n",
    "    mask = counts > 0\n",
    "    averaged_predictions = np.zeros_like(prediction_sum)\n",
    "    averaged_predictions[mask] = prediction_sum[mask] / counts[mask]\n",
    "    return averaged_predictions\n",
    "\n",
    "def viz_labels_and_predictions(sensor_data, y, model, window_size, stride, device, title):\n",
    "    \"\"\"\n",
    "    Visualize sensor data, true labels, and model predictions with smoothing.\n",
    "    \"\"\"\n",
    "    assert 'timestamp' in sensor_data.columns, \"Sensor data must include 'timestamp' column.\"\n",
    "    y_df = pd.DataFrame(y, columns=['labels'])\n",
    "    df = pd.concat([sensor_data, y_df], axis=1)\n",
    "    \n",
    "    prediction_sum = np.zeros(len(df))\n",
    "    counts = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(0, len(df) - window_size + 1, stride):\n",
    "        X_combined = preprocess_window(df, i, window_size).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = torch.sigmoid(model(X_combined)).cpu().numpy()[0]\n",
    "            prediction_sum[i:i + window_size] += logits\n",
    "            counts[i:i + window_size] += 1\n",
    "    \n",
    "    averaged_predictions = smooth_predictions(prediction_sum, counts) * 20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(dir):\n",
    "    txt_path = os.path.join(dir, f'desc.txt')\n",
    "    with open(txt_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    dic = eval(content)\n",
    "    return dic['window_size'], dic['stride'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in label a to tensor for ML\n",
    "def json_to_tensor(labels_x, acc_len_x, acc_x):\n",
    "    y_new = torch.zeros(acc_len_x)-1\n",
    "\n",
    "    bouts = []\n",
    "    for hand in labels_x:\n",
    "        for action in labels_x[hand]:\n",
    "            for bout in labels_x[hand][action]:\n",
    "                y_new[(acc_x.timestamp > bout['start']) & (acc_x.timestamp < bout['end'])] = (ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING[action] * 20 + 15)\n",
    "    return y_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "# print(model_path)\n",
    "\n",
    "# # Load model\n",
    "# model = torch.load(model_path)\n",
    "# model.eval()\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# # get recordings list\n",
    "# if recording == '*':\n",
    "#     recordings = sorted(os.listdir(WATCH_DIR))\n",
    "# else:\n",
    "#     recordings = [recording]\n",
    "\n",
    "# for rec in recordings:\n",
    "#     if rec == '.DS_Store':\n",
    "#         continue\n",
    "        \n",
    "#     print(f\"Processing recording: {rec}\")\n",
    "#     recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    \n",
    "#     sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    \n",
    "#     # get labels\n",
    "#     with open(f'{recording_dir}/labels.json', 'r') as f:\n",
    "#         labels = json.load(f)\n",
    "    \n",
    "#     # convert labels to tensor\n",
    "#     # data_len = len(sensor_data)\n",
    "#     # y = json_to_tensor(labels, data_len, sensor_data)\n",
    "    \n",
    "#     # # viz with predictions\n",
    "#     # viz_labels_and_predictions(\n",
    "#     #     sensor_data,\n",
    "#     #     y,\n",
    "#     #     model,\n",
    "#     #     window_size=window_size,\n",
    "#     #     stride=stride,\n",
    "#     #     device=device,\n",
    "#     #     title=recording_dir\n",
    "#     # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "# print(model_path)\n",
    "\n",
    "# # Load model\n",
    "# model = torch.load(model_path)\n",
    "# model.eval()\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# # get recordings list\n",
    "# if recording == '*':\n",
    "#     recordings = sorted(os.listdir(WATCH_DIR))\n",
    "# else:\n",
    "#     recordings = [recording]\n",
    "\n",
    "# for rec in recordings:\n",
    "#     if rec == '.DS_Store':\n",
    "#         continue\n",
    "        \n",
    "#     print(f\"Processing recording: {rec}\")\n",
    "#     recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    \n",
    "#     sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    \n",
    "#     # get labels\n",
    "#     with open(f'{recording_dir}/labels.json', 'r') as f:\n",
    "#         labels = json.load(f)\n",
    "    \n",
    "#     # convert labels to tensor\n",
    "#     # data_len = len(sensor_data)\n",
    "#     # y = json_to_tensor(labels, data_len, sensor_data)\n",
    "    \n",
    "#     # # viz with predictions\n",
    "#     # viz_labels_and_predictions(\n",
    "#     #     sensor_data,\n",
    "#     #     y,\n",
    "#     #     model,\n",
    "#     #     window_size=window_size,\n",
    "#     #     stride=stride,\n",
    "#     #     device=device,\n",
    "#     #     title=recording_dir\n",
    "#     # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bouts(recording_dir):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    all_starts = []\n",
    "    all_ends = []\n",
    "    \n",
    "    label_mapping = [\n",
    "        ('left', 'water', 0.0),\n",
    "        ('left', 'listerine', 1.0),\n",
    "        ('right', 'water', 0.0),\n",
    "        ('right', 'listerine', 1.0)\n",
    "    ]\n",
    "    \n",
    "    with open(os.path.join(recording_dir, 'labels.json')) as f:\n",
    "        labels = json.load(f)\n",
    "        \n",
    "    acc = pd.read_csv(os.path.join(recording_dir, 'acceleration.csv'), skiprows=1)\n",
    "    gyro = pd.read_csv(os.path.join(recording_dir, 'gyroscope.csv'), skiprows=1)\n",
    "    \n",
    "    #convert the timestap to sec\n",
    "    acc['timestamp'] = (acc['timestamp'] - acc['timestamp'].iloc[0]) * 1e-9\n",
    "    gyro['timestamp'] = (gyro['timestamp'] - gyro['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    merged_data = pd.merge_asof(acc, gyro, on='timestamp', \n",
    "                                suffixes=('_acc', '_gyro'))\n",
    "    \n",
    "    for side, liquid, label_value in label_mapping:\n",
    "        if side in labels and liquid in labels[side]:\n",
    "            for bout in labels[side][liquid]:\n",
    "                start_time = bout['start']\n",
    "                end_time = bout['end']\n",
    "                \n",
    "                # Extract data for this bout\n",
    "                bout_data = merged_data[\n",
    "                    (merged_data['timestamp'] >= start_time) & \n",
    "                    (merged_data['timestamp'] <= end_time)\n",
    "                ].copy()\n",
    "                \n",
    "                if len(bout_data) > 0:\n",
    "                    all_data.extend(bout_data)\n",
    "                    all_labels.append(label_value)\n",
    "                    all_starts.append(start_time)\n",
    "                    all_ends.append(end_time)\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Rename col\n",
    "    combined_df = combined_df.rename(columns={\n",
    "        'x_acc': 'acc_x',\n",
    "        'y_acc': 'acc_y',\n",
    "        'z_acc': 'acc_z',\n",
    "        'x_gyro': 'gyro_x',\n",
    "        'y_gyro': 'gyro_y',\n",
    "        'z_gyro': 'gyro_z'\n",
    "    })\n",
    "\n",
    "    #reorder them \n",
    "    columns = ['timestamp', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    combined_df = combined_df[columns]\n",
    "\n",
    "    return combined_df, all_labels, all_starts, all_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, device, bout, label, window_size, stride):\n",
    "    assert 'timestamp' in bout.columns, \"Sensor data must include 'timestamp' column.\"\n",
    "    y_df = pd.DataFrame(label, columns=['labels'])\n",
    "    df = pd.concat([bout, y_df], axis=1)\n",
    "    \n",
    "    prediction_sum = np.zeros(len(df))\n",
    "    counts = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(0, len(df) - window_size + 1, stride):\n",
    "        X_combined = preprocess_window(df, i, window_size).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = torch.sigmoid(model(X_combined)).cpu().numpy()[0]\n",
    "            prediction_sum[i:i + window_size] += logits\n",
    "            counts[i:i + window_size] += 1\n",
    "    \n",
    "    return prediction_sum, counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(recording_dir):\n",
    "    acc = pd.read_csv(f'{recording_dir}/acceleration.csv', skiprows=1)\n",
    "    acc['timestamp'] = (acc['timestamp'] - acc['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    gyro = pd.read_csv(f'{recording_dir}/gyroscope.csv', skiprows=1)\n",
    "    gyro['timestamp'] = (gyro['timestamp'] - gyro['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    # interpolate gyro data to match acc timestamps\n",
    "    gyro_interp = pd.DataFrame()\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        gyro_interp[axis] = np.interp(acc['timestamp'], gyro['timestamp'], gyro[axis])\n",
    "    \n",
    "    # combine acc and gyro data\n",
    "    sensor_data = pd.DataFrame()\n",
    "    sensor_data['timestamp'] = acc['timestamp']\n",
    "    sensor_data['acc_x'] = acc['x']\n",
    "    sensor_data['acc_y'] = acc['y']\n",
    "    sensor_data['acc_z'] = acc['z']\n",
    "    sensor_data['gyro_x'] = gyro_interp['x']\n",
    "    sensor_data['gyro_y'] = gyro_interp['y']\n",
    "    sensor_data['gyro_z'] = gyro_interp['z']\n",
    "    \n",
    "    return sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7/res_search_00_7_bestF1.pth\n",
      "Using device: cuda:1\n",
      "Processing recording: 2023-07-18_07_21_53\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#get bouts\u001b[39;00m\n\u001b[1;32m     31\u001b[0m sensor_data \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(recording_dir)\n\u001b[0;32m---> 32\u001b[0m all_bouts, all_labels, all_starts, all_ends \u001b[38;5;241m=\u001b[39m \u001b[43mget_bouts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m yhat_full_len \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(sensor_data)) \u001b[38;5;66;03m#will ve all zeros then will add in the smoothed preds at the right indexes\u001b[39;00m\n\u001b[1;32m     35\u001b[0m y_full_len \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(sensor_data)) \u001b[38;5;66;03m#will ve all zeros then will add in the true y at the right indexes\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 45\u001b[0m, in \u001b[0;36mget_bouts\u001b[0;34m(recording_dir)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 all_starts\u001b[38;5;241m.\u001b[39mappend(start_time)\n\u001b[1;32m     43\u001b[0m                 all_ends\u001b[38;5;241m.\u001b[39mappend(end_time)\n\u001b[0;32m---> 45\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Rename col\u001b[39;00m\n\u001b[1;32m     48\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_x\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_y\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_gyro\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgyro_z\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     55\u001b[0m })\n",
      "File \u001b[0;32m~/.virenv/base/lib/python3.10/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.virenv/base/lib/python3.10/site-packages/pandas/core/reshape/concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m~/.virenv/base/lib/python3.10/site-packages/pandas/core/reshape/concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "sys.path.append(path_to_model_def)\n",
    "head_tail = os.path.split(path_to_dir_with_model_pt_file)\n",
    "model_path = os.path.join(path_to_dir_with_model_pt_file, f'{head_tail[1]}_bestF1.pth')\n",
    "\n",
    "\n",
    "#get model and meta data\n",
    "window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "print(model_path)\n",
    "\n",
    "# load model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# for each recording do the viz recording\n",
    "if recording == '*':\n",
    "    recordings = sorted(os.listdir(WATCH_DIR))\n",
    "else:\n",
    "    recordings = [recording]\n",
    "\n",
    "for rec in recordings:\n",
    "    if rec == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing recording: {rec}\")\n",
    "    recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    #get bouts\n",
    "    sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    all_bouts, all_labels, all_starts, all_ends = get_bouts(recording_dir)\n",
    "\n",
    "    yhat_full_len = np.zeros(len(sensor_data)) #will ve all zeros then will add in the smoothed preds at the right indexes\n",
    "    y_full_len = np.zeros(len(sensor_data)) #will ve all zeros then will add in the true y at the right indexes\n",
    "\n",
    "    print(len(yhat_full_len))\n",
    "    for bout, label, start, end in all_bouts, all_labels, all_starts, all_ends:\n",
    "        pred_sum, pred_count = get_preds(model, device, bout, label, window_size, stride).to(device) #partition inot widows and combine with the true value\n",
    "        avg_preds = smooth_predictions(pred_sum, pred_count)\n",
    "\n",
    "        yhat_full_len[start:end] = avg_preds\n",
    "        y_full_len[start:end] = label\n",
    "\n",
    "\n",
    "    \n",
    "    # Visualization\n",
    "    fig = go.Figure()\n",
    "    sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    for col in sensor_cols:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sensor_data['timestamp'], y=sensor_data['acc_x','acc_y','acc_x'],\n",
    "            name=f'{col.capitalize()}',\n",
    "            mode='lines', opacity=0.7\n",
    "        ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=sensor_data['timestamp'], y=y_full_len,\n",
    "        name='True Labels', mode='lines',\n",
    "        line=dict(color='black', width=2)\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=sensor_data['timestamp'], y=yhat_full_len,\n",
    "        name='Predictions', mode='lines',\n",
    "        line=dict(color='red', width=3, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title, xaxis_title='Time (s)',\n",
    "        yaxis_title='Value', template='plotly',\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "    )\n",
    "    fig.show(renderer='browser')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
