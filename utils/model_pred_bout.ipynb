{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theme = 'plotly_dark'\n",
    "theme = 'seaborn'\n",
    "#theme = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "path_to_model_def = '/home/kuba/Projects/MedicationTakingData/resmodel' #this is were the .py file is \n",
    "path_to_dir_with_model_pt_file = '/home/kuba/Projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7'\n",
    "\n",
    "#the watch and recoding we willbe evaling\n",
    "WATCH_DIR = '/home/kuba/Documents/Data/Raw/Listerine/3_final/03'\n",
    "recording = '2023-07-18_07_21_53'\n",
    "\n",
    "HERTZ = 100\n",
    "ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING = {\n",
    "    'water':0,\n",
    "    'listerine':1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_window(df, start, window_size):\n",
    "    \"\"\"\n",
    "    Prepare a window of accelerometer and gyroscope data for the model.\n",
    "    \"\"\"\n",
    "    window = df.iloc[start:start + window_size]\n",
    "    # Prepare accelerometer and gyroscope data\n",
    "    X_acc = torch.tensor([window[col].values for col in ['acc_x', 'acc_y', 'acc_z']], dtype=torch.float32)\n",
    "    X_gyro = torch.tensor([window[col].values for col in ['gyro_x', 'gyro_y', 'gyro_z']], dtype=torch.float32)\n",
    "    # Combine [1, 6, window_size]\n",
    "    return torch.cat((X_acc, X_gyro), dim=0).unsqueeze(0)\n",
    "\n",
    "def smooth_predictions(prediction_sum, counts):\n",
    "    \"\"\"\n",
    "    Smooth predictions by averaging, handling divisions by zero.\n",
    "    \"\"\"\n",
    "    mask = counts > 0\n",
    "    averaged_predictions = np.zeros_like(prediction_sum)\n",
    "    averaged_predictions[mask] = prediction_sum[mask] / counts[mask]\n",
    "    return averaged_predictions\n",
    "\n",
    "def viz_labels_and_predictions(sensor_data, y, model, window_size, stride, device, title):\n",
    "    \"\"\"\n",
    "    Visualize sensor data, true labels, and model predictions with smoothing.\n",
    "    \"\"\"\n",
    "    assert 'timestamp' in sensor_data.columns, \"Sensor data must include 'timestamp' column.\"\n",
    "    y_df = pd.DataFrame(y, columns=['labels'])\n",
    "    df = pd.concat([sensor_data, y_df], axis=1)\n",
    "    \n",
    "    prediction_sum = np.zeros(len(df))\n",
    "    counts = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(0, len(df) - window_size + 1, stride):\n",
    "        X_combined = preprocess_window(df, i, window_size).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = torch.sigmoid(model(X_combined)).cpu().numpy()[0]\n",
    "            prediction_sum[i:i + window_size] += logits\n",
    "            counts[i:i + window_size] += 1\n",
    "    \n",
    "    averaged_predictions = smooth_predictions(prediction_sum, counts) * 20\n",
    "    \n",
    "    # Visualization\n",
    "    fig = go.Figure()\n",
    "    sensor_cols = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    for col in sensor_cols:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['timestamp'], y=df[col],\n",
    "            name=f'{col.capitalize()}',\n",
    "            mode='lines', opacity=0.7\n",
    "        ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=df['labels'],\n",
    "        name='True Labels', mode='lines',\n",
    "        line=dict(color='black', width=2)\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['timestamp'], y=averaged_predictions,\n",
    "        name='Predictions', mode='lines',\n",
    "        line=dict(color='red', width=3, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title, xaxis_title='Time (s)',\n",
    "        yaxis_title='Value', template='plotly',\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "    )\n",
    "    fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(dir):\n",
    "    txt_path = os.path.join(dir, f'desc.txt')\n",
    "    with open(txt_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    dic = eval(content)\n",
    "    return dic['window_size'], dic['stride'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(recording_dir):\n",
    "    acc = pd.read_csv(f'{recording_dir}/acceleration.csv', skiprows=1)\n",
    "    acc['timestamp'] = (acc['timestamp'] - acc['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    gyro = pd.read_csv(f'{recording_dir}/gyroscope.csv', skiprows=1)\n",
    "    gyro['timestamp'] = (gyro['timestamp'] - gyro['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    # interpolate gyro data to match acc timestamps\n",
    "    gyro_interp = pd.DataFrame()\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        gyro_interp[axis] = np.interp(acc['timestamp'], gyro['timestamp'], gyro[axis])\n",
    "    \n",
    "    # combine acc and gyro data\n",
    "    sensor_data = pd.DataFrame()\n",
    "    sensor_data['timestamp'] = acc['timestamp']\n",
    "    sensor_data['acc_x'] = acc['x']\n",
    "    sensor_data['acc_y'] = acc['y']\n",
    "    sensor_data['acc_z'] = acc['z']\n",
    "    sensor_data['gyro_x'] = gyro_interp['x']\n",
    "    sensor_data['gyro_y'] = gyro_interp['y']\n",
    "    sensor_data['gyro_z'] = gyro_interp['z']\n",
    "    \n",
    "    return sensor_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in label a to tensor for ML\n",
    "def json_to_tensor(labels_x, acc_len_x, acc_x):\n",
    "    y_new = torch.zeros(acc_len_x)-1\n",
    "\n",
    "    bouts = []\n",
    "    for hand in labels_x:\n",
    "        for action in labels_x[hand]:\n",
    "            for bout in labels_x[hand][action]:\n",
    "                y_new[(acc_x.timestamp > bout['start']) & (acc_x.timestamp < bout['end'])] = (ACTIVITY_NAME_TO_CLASS_INDEX_MAPPING[action] * 20 + 15)\n",
    "    return y_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/MedicationTakingData/resmodel/res_search_00/res_search_00_7/res_search_00_7_bestF1.pth\n",
      "Using device: cuda:1\n",
      "Processing recording: 2023-07-18_07_21_53\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(path_to_model_def)\n",
    "head_tail = os.path.split(path_to_dir_with_model_pt_file)\n",
    "model_path = os.path.join(path_to_dir_with_model_pt_file, f'{head_tail[1]}_bestF1.pth')\n",
    "\n",
    "window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "print(model_path)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# get recordings list\n",
    "if recording == '*':\n",
    "    recordings = sorted(os.listdir(WATCH_DIR))\n",
    "else:\n",
    "    recordings = [recording]\n",
    "\n",
    "for rec in recordings:\n",
    "    if rec == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing recording: {rec}\")\n",
    "    recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    \n",
    "    sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    \n",
    "    # get labels\n",
    "    with open(f'{recording_dir}/labels.json', 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "    # convert labels to tensor\n",
    "    # data_len = len(sensor_data)\n",
    "    # y = json_to_tensor(labels, data_len, sensor_data)\n",
    "    \n",
    "    # # viz with predictions\n",
    "    # viz_labels_and_predictions(\n",
    "    #     sensor_data,\n",
    "    #     y,\n",
    "    #     model,\n",
    "    #     window_size=window_size,\n",
    "    #     stride=stride,\n",
    "    #     device=device,\n",
    "    #     title=recording_dir\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "print(model_path)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# get recordings list\n",
    "if recording == '*':\n",
    "    recordings = sorted(os.listdir(WATCH_DIR))\n",
    "else:\n",
    "    recordings = [recording]\n",
    "\n",
    "for rec in recordings:\n",
    "    if rec == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing recording: {rec}\")\n",
    "    recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    \n",
    "    sensor_data = load_and_preprocess_data(recording_dir)\n",
    "    \n",
    "    # get labels\n",
    "    with open(f'{recording_dir}/labels.json', 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "    # convert labels to tensor\n",
    "    # data_len = len(sensor_data)\n",
    "    # y = json_to_tensor(labels, data_len, sensor_data)\n",
    "    \n",
    "    # # viz with predictions\n",
    "    # viz_labels_and_predictions(\n",
    "    #     sensor_data,\n",
    "    #     y,\n",
    "    #     model,\n",
    "    #     window_size=window_size,\n",
    "    #     stride=stride,\n",
    "    #     device=device,\n",
    "    #     title=recording_dir\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bouts(recording_dir)\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    all_starts = []\n",
    "    all_ends = []\n",
    "    \n",
    "    label_mapping = [\n",
    "        ('left', 'water', 0.0),\n",
    "        ('left', 'listerine', 1.0),\n",
    "        ('right', 'water', 0.0),\n",
    "        ('right', 'listerine', 1.0)\n",
    "    ]\n",
    "    \n",
    "    with open(os.path.join(recording_path, 'labels.json')) as f:\n",
    "        labels = json.load(f)\n",
    "        \n",
    "    acc = pd.read_csv(os.path.join(recording_path, 'acceleration.csv'), skiprows=1)\n",
    "    gyro = pd.read_csv(os.path.join(recording_path, 'gyroscope.csv'), skiprows=1)\n",
    "    \n",
    "    #convert the timestap to sec\n",
    "    acc['timestamp'] = (acc['timestamp'] - acc['timestamp'].iloc[0]) * 1e-9\n",
    "    gyro['timestamp'] = (gyro['timestamp'] - gyro['timestamp'].iloc[0]) * 1e-9\n",
    "    \n",
    "    merged_data = pd.merge_asof(acc, gyro, on='timestamp', \n",
    "                                suffixes=('_acc', '_gyro'))\n",
    "    \n",
    "    for side, liquid, label_value in label_mapping:\n",
    "        if side in labels and liquid in labels[side]:\n",
    "            for bout in labels[side][liquid]:\n",
    "                start_time = bout['start']\n",
    "                end_time = bout['end']\n",
    "                \n",
    "                # Extract data for this bout\n",
    "                bout_data = merged_data[\n",
    "                    (merged_data['timestamp'] >= start_time) & \n",
    "                    (merged_data['timestamp'] <= end_time)\n",
    "                ].copy()\n",
    "                \n",
    "                if len(bout_data) > 0:\n",
    "                    all_data.append(bout_data)\n",
    "                    all_labels.append(label_value)\n",
    "                    all_starts.append(start_time)\n",
    "                    all_ends.append(end_time)\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Rename col\n",
    "    combined_df = combined_df.rename(columns={\n",
    "        'x_acc': 'acc_x',\n",
    "        'y_acc': 'acc_y',\n",
    "        'z_acc': 'acc_z',\n",
    "        'x_gyro': 'gyro_x',\n",
    "        'y_gyro': 'gyro_y',\n",
    "        'z_gyro': 'gyro_z'\n",
    "    })\n",
    "\n",
    "    #reorder them \n",
    "    columns = ['timestamp', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    combined_df = combined_df[columns]\n",
    "\n",
    "    return combined_df, all_labels, all_starts, all_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model and meta data\n",
    "window_size, stride = read_txt(path_to_dir_with_model_pt_file)\n",
    "print(model_path)\n",
    "\n",
    "# load model\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# for each recording do the viz recording\n",
    "if recording == '*':\n",
    "    recordings = sorted(os.listdir(WATCH_DIR))\n",
    "else:\n",
    "    recordings = [recording]\n",
    "\n",
    "for rec in recordings:\n",
    "    if rec == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing recording: {rec}\")\n",
    "    recording_dir = f'{WATCH_DIR}/{rec}'\n",
    "    #get bouts\n",
    "    all_bouts, all_labels, all_starts, all_ends = get_bouts(recording_dir)\n",
    "\n",
    "    for bout, label, start, end in all_bouts, all_labels, all_starts, all_ends:\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
